{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Commenting in a Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the folder where the data are saved\n",
    "filePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/Annual/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV\n",
    "fileName = 'endpoint_documents_PS_2020.csv'\n",
    "with open(filePath+fileName,'r',encoding='utf-8') as loadfile:\n",
    "    df2020 = pd.read_csv(loadfile, index_col='index')\n",
    "df2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten/rename number of comments received column\n",
    "df2020 = df2020.rename(columns={'numberOfCommentsReceived': 'commentsReceived'})\n",
    "\n",
    "# create posted count column\n",
    "df2020['commentsPosted'] = 1\n",
    "\n",
    "df2020.loc[:,['commentsPosted','commentsReceived']].query('commentsReceived > 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for documentId's of entries to clean\n",
    "cleaning_list = []\n",
    "type(cleaning_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates and Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns for year and month\n",
    "df2020['postedYear'] = df2020['postedDate'].str.slice(start=0,stop=4)\n",
    "df2020['postedMonth'] = df2020['postedDate'].str.slice(start=6,stop=7)\n",
    "\n",
    "# convert to integers\n",
    "df2020['postedYear'] = pd.to_numeric(df2020['postedYear'])\n",
    "df2020['postedMonth'] = pd.to_numeric(df2020['postedMonth'])\n",
    "\n",
    "# return new columns\n",
    "print(df2020.loc[:,['postedYear','postedMonth']].dtypes)\n",
    "df2020.loc[:,['postedYear','postedMonth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created new column with postedDate in datetime format\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "df2020['postedDatetime'] = pd.to_datetime(df2020['postedDate'], utc=True)\n",
    "df2020.loc[:,['postedDate','postedDatetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot by month\n",
    "by_YearMonth = pd.pivot_table(df2020,values=['commentsPosted','commentsReceived'],\n",
    "                              columns=['postedYear'],\n",
    "                              index=['postedMonth'],\n",
    "                              aggfunc=np.sum, margins=False)\n",
    "\n",
    "by_YearMonth.loc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query entries with Month == 6\n",
    "queries = df2020.loc[:,['postedMonth','postedDate','documentId']].query('postedMonth == 6')\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cleaning list\n",
    "docs_to_add = {'fix_month':\n",
    "             queries.loc[:,'documentId'].tolist()}\n",
    "cleaning_list.append(docs_to_add)\n",
    "print(cleaning_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Retrieve receivedDates for comments where Month==6 ----- #\n",
    "import requests\n",
    "\n",
    "# general variables for setting parameters\n",
    "APIkey = \"fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC\"\n",
    "baseURL = \"https://api.data.gov:443/regulations/v3/document.json?\"\n",
    "dctId = \"\"\n",
    "\n",
    "# set parameters\n",
    "params = {'api_key': APIkey,\n",
    "          'documentId': dctId}\n",
    "\n",
    "# create objects for \n",
    "fix_month = cleaning_list[0]['fix_month']\n",
    "range_fix = len(fix_month)\n",
    "receivedFix = [] # list for adding receivedDate\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "for d in range(range_fix):\n",
    "    dctId = fix_month[d]\n",
    "    params.update({'documentId': dctId})\n",
    "\n",
    "    dct_response = requests.get(baseURL, params=params)\n",
    "    RL_remaining = int(dct_response.headers['X-RateLimit-Remaining'])\n",
    "\n",
    "    if dct_response.status_code != 200:\n",
    "        print('code '+str(dct_response.status_code)+' for page #'+str(pageIndex), \n",
    "              dct_response.text, sep='\\n')\n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 1 minute...\", sep='\\n')\n",
    "        time.sleep(60)\n",
    "\n",
    "    this_receivedDate = dct_response.json()['receivedDate']\n",
    "    receivedFix.append(this_receivedDate)\n",
    "\n",
    "print('Length of receivedFix is '+str(len(receivedFix)))\n",
    "\n",
    "# replace postedDate with receivedDate for incorrect entries\n",
    "fix_list = list(zip(fix_month,receivedFix))\n",
    "\n",
    "for n in range(len(fix_list)):\n",
    "    bool_fix = [True if item in fix_list[n][0] else False for item in df2020.loc[:,'documentId'].tolist()]\n",
    "    df2020.loc[bool_fix,'postedDate'] = fix_list[n][1]\n",
    "\n",
    "    # revise year and month columns\n",
    "    df2020.loc[bool_fix,'postedYear'] = int(fix_list[n][1][0:4])\n",
    "    df2020.loc[bool_fix,'postedMonth'] = int(fix_list[n][1][6:7])\n",
    "\n",
    "\n",
    "# check if any obs have Month==6\n",
    "queries = df2020.loc[:,['postedMonth','postedDate','documentId']].query('postedMonth == 6')\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agency groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_Agency = pd.pivot_table(df2020,\n",
    "                           values=['commentsPosted','commentsReceived'],\n",
    "                           index=['agencyAcronym'],\n",
    "                           aggfunc=np.sum, margins=False)\n",
    "print(len(by_Agency))\n",
    "by_Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list = by_Agency.index.tolist()\n",
    "print(len(agency_list),'\\n')\n",
    "print(agency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for Branch to Agency lookups\n",
    "branch_dict = {'Judicial': ['USC'], \n",
    "               'Legislative': ['LOC', 'COLC'], \n",
    "               'Independent': ['AID', 'ATBCB', 'CFPB', 'CNCS', 'CPSC', 'CSB', 'EAC', \n",
    "                               'EEOC', 'FRTIB', 'FTC', 'GSA', 'NARA', 'NCUA', 'NLRB', \n",
    "                               'NRC', 'NTSB', 'OPM', 'PBGC', 'SBA', 'SSA'], \n",
    "               'Executive': ['DHS', 'CISA', 'FEMA', 'TSA', 'USCBP', 'USCG', 'USCIS', \n",
    "                             'DOC', 'BIS', 'ITA', 'NIST', 'NOAA', 'PTO', 'USBC', 'DOD', \n",
    "                             'COE', 'DARS', 'USA', 'USAF', 'DOE', 'EERE', 'DOI', 'BIA', \n",
    "                             'BLM', 'BOR', 'BSEE', 'FWS', 'NPS', 'OSM', 'DOJ', 'BOP', 'DEA', \n",
    "                             'EOIR', 'DOL', 'ETA', 'LMSO', 'MSHA', 'OFCCP', 'OSHA', 'WCPO', \n",
    "                             'DOS', 'DOT', 'FAA', 'FHWA', 'FMCSA', 'FRA', 'FTA', 'MARAD', \n",
    "                             'NHTSA', 'PHMSA', 'ED', 'EOP', 'CEQ', 'OMB', 'USTR', 'EPA', 'FAR', 'HHS', 'ATSDR', 'CDC', 'CMS', 'FDA', 'HHSIG', 'HRSA', 'HUD', 'TREAS', 'FINCEN', 'FISCAL', 'IRS', 'OCC', 'TTB', 'USDA', \n",
    "                             'AMS', 'APHIS', 'CCC', 'FCIC', 'FNS', 'FS', 'FSA', 'FSIS', \n",
    "                             'NRCS', 'RBS', 'RHS', 'RUS', 'VA']\n",
    "              }\n",
    "print(len(branch_dict))\n",
    "print(branch_dict['Independent'])\n",
    "print(len(branch_dict['Judicial']+\n",
    "          branch_dict['Legislative']+\n",
    "          branch_dict['Independent']+\n",
    "          branch_dict['Executive']) - len(['LOC','EOP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# references:\n",
    "    # https://stackoverflow.com/questions/49161120/pandas-python-set-value-of-one-column-based-on-value-in-another-column\n",
    "    # https://stackoverflow.com/questions/30446510/list-of-elements-to-boolean-array\n",
    "\n",
    "# create boolean arrays for each branch\n",
    "bool_jud = [True if item in branch_dict['Judicial'] else False for item in df2020.loc[:,'agencyAcronym'].tolist()]\n",
    "bool_leg = [True if item in branch_dict['Legislative'] else False for item in df2020.loc[:,'agencyAcronym'].tolist()]\n",
    "bool_ind = [True if item in branch_dict['Independent'] else False for item in df2020.loc[:,'agencyAcronym'].tolist()]\n",
    "bool_exe = [True if item in branch_dict['Executive'] else False for item in df2020.loc[:,'agencyAcronym'].tolist()]\n",
    "\n",
    "# create new column for branch\n",
    "df2020['agencyBranch'] = ''\n",
    "\n",
    "# use boolean arrays to fill new column\n",
    "df2020.loc[bool_jud,'agencyBranch'] = 'Judicial'\n",
    "df2020.loc[bool_leg,'agencyBranch'] = 'Legislative'\n",
    "df2020.loc[bool_ind,'agencyBranch'] = 'Independent'\n",
    "df2020.loc[bool_exe,'agencyBranch'] = 'Executive'\n",
    "\n",
    "df2020.loc[:,['agencyAcronym','agencyBranch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query df by branch\n",
    "df2020.query('agencyBranch == \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query df by multiple branches\n",
    "df2020.query('agencyBranch == \"Legislative\" | agencyBranch == \"Judicial\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict for Parent Agencies\n",
    "parent_dict = dict(LOC = ['LOC', 'COLC'], \n",
    "                   DHS = ['DHS', 'CISA', 'FEMA', 'TSA', 'USCBP', 'USCG', 'USCIS'],\n",
    "                   DOC = ['DOC', 'BIS', 'ITA', 'NIST', 'NOAA', 'PTO', 'USBC'],\n",
    "                   DOD = ['DOD', 'COE', 'DARS', 'USA', 'USAF'],\n",
    "                   DOE = ['DOE', 'EERE'],\n",
    "                   DOI = ['DOI', 'BIA', 'BLM', 'BOR', 'BSEE', 'FWS', 'NPS', 'OSM'],\n",
    "                   DOJ = ['DOJ', 'BOP', 'DEA', 'EOIR'],\n",
    "                   DOL = ['DOL', 'ETA', 'LMSO', 'MSHA', 'OFCCP', 'OSHA', 'WCPO'],\n",
    "                   DOS = ['DOS'],\n",
    "                   DOT = ['DOT', 'FAA', 'FHWA', 'FMCSA', 'FRA', 'FTA', 'MARAD', 'NHTSA', 'PHMSA'],\n",
    "                   ED = ['ED'],\n",
    "                   EOP = ['EOP', 'CEQ', 'OMB', 'USTR'],\n",
    "                   EPA = ['EPA'],\n",
    "                   FAR = ['FAR'],\n",
    "                   HHS = ['HHS', 'ATSDR', 'CDC', 'CMS', 'FDA', 'HHSIG', 'HRSA'],\n",
    "                   HUD = ['HUD'],\n",
    "                   TREAS = ['TREAS', 'FINCEN', 'FISCAL', 'IRS', 'OCC', 'TTB'],\n",
    "                   USDA = ['USDA', 'AMS', 'APHIS', 'CCC', 'FCIC', 'FNS', 'FS', 'FSA', 'FSIS', 'NRCS', 'RBS', 'RHS', 'RUS'],\n",
    "                   VA = ['VA']\n",
    "                  )\n",
    "\n",
    "x = 1\n",
    "print(list(parent_dict.keys())[x])\n",
    "print(list(parent_dict.values())[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create new column for parent agency\n",
    "df2020['agencyParent'] = ''\n",
    "\n",
    "# parent==acronym for judicial & independent agencies\n",
    "df2020.loc[bool_jud,'agencyParent'] = df2020.loc[bool_jud,'agencyAcronym']\n",
    "df2020.loc[bool_ind,'agencyParent'] = df2020.loc[bool_ind,'agencyAcronym']\n",
    "\n",
    "# set parent for executive & legislative agencies\n",
    "dictLength = len(parent_dict)\n",
    "listValues = list(parent_dict.values())\n",
    "listKeys = list(parent_dict.keys())\n",
    "\n",
    "for key in range(dictLength):\n",
    "    print(list(parent_dict.keys())[key])\n",
    "    bool_array = [True if item in listValues[key] else False for item in df2020.loc[:,'agencyAcronym'].tolist()]\n",
    "    df2020.loc[bool_array,'agencyParent'] = [listKeys[key] if item in listValues[key] else '' for item in df2020.loc[bool_array,'agencyAcronym'].tolist()]\n",
    "\n",
    "df2020.loc[:,['agencyAcronym','agencyParent','agencyBranch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.loc[:,['agencyAcronym','agencyParent','agencyBranch']].query('agencyParent == \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2020.query('agencyBranch == \"Independent\"')) + \n",
    "      len(df2020.query('agencyBranch == \"Judicial\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_AgencyParent = pd.pivot_table(df2020,\n",
    "                           values=['commentsPosted','commentsReceived'],\n",
    "                           index=['agencyBranch','agencyParent'],\n",
    "                           aggfunc=np.sum, margins=False)\n",
    "print(len(by_AgencyParent))\n",
    "by_AgencyParent.query('agencyBranch == \"Executive\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC, Duplicate, or Significantly Similar Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view MCC comments that are posted as \"Representative\" comments\n",
    "    # e.g., \"This agency received 21 duplicate or significantly similar comments.\"\n",
    "    # Ex: https://www.regulations.gov/document?D=FNS-2019-0009-5664\n",
    "lookup = ['documentId','title','organization','attachmentCount','commentsPosted','commentsReceived','agencyAcronym','agencyParent','agencyBranch']\n",
    "\n",
    "df2020.loc[:,lookup].query('commentsReceived != commentsPosted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bool array for agency-marked MCCs (i.e., representative comments)\n",
    "bool_MCC = df2020['commentsPosted']!=df2020['commentsReceived']\n",
    "print(bool_MCC.value_counts(),'\\n')\n",
    "\n",
    "# create bool array for comments to group as representative\n",
    "    # reference for regex: https://docs.python.org/3/howto/regex.html\n",
    "bool_group = df2020.loc[:,'title'].str.contains('MM[\\d]+|Mass Mail|Mass Comment', regex=True, case=True)\n",
    "print(bool_group.value_counts(),'\\n')\n",
    "\n",
    "# create bool array for comments that overlap (both R&G)\n",
    "bool_RnG = bool_MCC & bool_group\n",
    "print(bool_RnG.value_counts(),'\\n')\n",
    "\n",
    "# create new column\n",
    "df2020['MCCfilter'] = 'Unique'\n",
    "\n",
    "# use boolean arrays to fill new column\n",
    "df2020.loc[bool_MCC,'MCCfilter'] = 'Representative'\n",
    "df2020.loc[bool_group,'MCCfilter'] = 'Grouped'\n",
    "df2020.loc[bool_RnG,'MCCfilter'] = 'Both R&G'\n",
    "\n",
    "# convert new column to categorical\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype\n",
    "df2020 = df2020.astype({'MCCfilter': 'category'})\n",
    "print(df2020.loc[:,'MCCfilter'].value_counts())\n",
    "\n",
    "df2020.loc[:,['documentId','docketId','agencyAcronym','title','commentsPosted','commentsReceived','MCCfilter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.loc[:,['MCCfilter','title','commentsPosted','commentsReceived']].query('MCCfilter == \"Both R&G\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_MCCfilter = pd.pivot_table(df2020, values=['commentsPosted','commentsReceived'],\n",
    "                              index=['MCCfilter'],\n",
    "                              aggfunc=np.sum, margins=True)\n",
    "\n",
    "by_MCCfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter comments for grouping\n",
    "MMfilter = df2020.loc[np.array(df2020['MCCfilter']=='Grouped') | np.array(df2020['MCCfilter']=='Both R&G'),:]\n",
    "\n",
    "pd.pivot_table(MMfilter, \n",
    "               values=['commentsPosted','commentsReceived'], \n",
    "               index=['docketId'], \n",
    "               aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine number of MCC campaigns in docket and verify tally of comments\n",
    "docket = 'CEQ-2019-0003'\n",
    "restriction = MMfilter['docketId']==docket\n",
    "obs = 1\n",
    "num = 0\n",
    "massTally = num\n",
    "obsTally = []\n",
    "\n",
    "while obs > 0:\n",
    "    # use two different regex patterns -- Mass Mail Campaign #\\\\b and MMx#\\\\b\n",
    "    bool_lookup = MMfilter.loc[restriction,'title'].str.contains('Mass Mail Campaign '+str(num)+r'\\b|MM'+str(num)+r'\\b',\n",
    "                                                                 regex=True, case=True)\n",
    "    \n",
    "    try: # try 1\n",
    "        obs = int(bool_lookup.value_counts()[True])\n",
    "        print('MCC '+str(num)+' -- obs = '+str(obs))\n",
    "        massTally = num\n",
    "        obsTally.extend([obs])\n",
    "    except:\n",
    "        print('Error occurred for MCC'+str(num))\n",
    "        try: # try 2\n",
    "            num = num + 1\n",
    "            bool_lookup = MMfilter.loc[restriction,'title'].str.contains('Mass Mail Campaign '+str(num)+r'\\b|MM'+str(num)+r'\\b', regex=True, case=True)\n",
    "            obs = int(bool_lookup.value_counts()[True])\n",
    "        except:\n",
    "            print('Error occurred for MCC'+str(num))\n",
    "            try: # try 3\n",
    "                num = num + 1\n",
    "                bool_lookup = MMfilter.loc[MMfilter['docketId']!=docket,'title'].str.contains('Mass Mail Campaign '+str(num)+r'\\b|MM'+str(num)+r'\\b', regex=True, case=True)\n",
    "                obs = int(bool_lookup.value_counts()[True])\n",
    "            except:\n",
    "                print('Error occurred for MCC'+str(num))\n",
    "                obs = 0\n",
    "    else:\n",
    "        num = num + 1\n",
    "\n",
    "print('MCC tally = '+str(massTally)+' -- obs tally = '+str(sum(obsTally)))\n",
    "print(len(MMfilter.loc[restriction,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# mission: create new DataFrame of CEQ MCC campaigns for merging with df2020\n",
    "\n",
    "# create lists for populating df columns\n",
    "idList = [] ## documentId\n",
    "titleList = [] ## title\n",
    "numList = [] ## MCC number\n",
    "obsList = [] ## comments posted for an MCC\n",
    "\n",
    "# populate lists with for loop and regex\n",
    "for num in range(massTally+1):\n",
    "    regex_search = 'Mass Mail Campaign '+str(num)+r'\\b|MM'+str(num)+r'\\b'\n",
    "    bool_search = MMfilter.loc[restriction,'title'].str.contains(regex_search,\n",
    "                                                                 regex=True, case=True)\n",
    "    try: # try 1\n",
    "        idList.extend(MMfilter.loc[restriction,:].loc[bool_search,'documentId'].tolist())\n",
    "        titleList.extend(MMfilter.loc[restriction,:].loc[bool_search,'title'].tolist())\n",
    "        obs = int(bool_search.value_counts()[True])\n",
    "        obsList.extend([obs]*obs)\n",
    "        numList.extend([num]*obs)\n",
    "        if num%50==0:\n",
    "            print('Just finished MCC'+str(num))\n",
    "    except:\n",
    "        print('Error occurred for MCC'+str(num))\n",
    "        continue\n",
    "\n",
    "# zip lists into new list and generate df\n",
    "dataList = list(zip(idList,titleList,numList,obsList))\n",
    "dfCEQMCC = pd.DataFrame(dataList, columns = ['documentId', 'title', 'MCCnumber', 'commentsGrouped'])\n",
    "\n",
    "# check whether length of new df is correct\n",
    "if len(dfCEQMCC) == len(MMfilter.loc[restriction,:]):\n",
    "    print(dfCEQMCC.info())\n",
    "else:\n",
    "    print('Check DataFrame before merge. It might be missing entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2020))\n",
    "df2020Grouped = df2020.merge(dfCEQMCC, how='outer', on=['documentId','title'], indicator=True, validate='1:1')\n",
    "df2020Grouped = df2020Grouped.rename(columns={\"_merge\": \"_merge_CEQMCC\"})\n",
    "df2020Grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df2020Grouped, values=['commentsGrouped','commentsPosted'],\n",
    "               index=['postedMonth'], columns=['MCCfilter'],\n",
    "               aggfunc='count', dropna=False, fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df2020Grouped, values=['commentsGrouped','commentsPosted'],\n",
    "               index=['_merge_CEQMCC'],\n",
    "               aggfunc='count', dropna=False, fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign representative comments for MCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for representative comment\n",
    "df2020Grouped['represent'] = 'Fill'\n",
    "\n",
    "bool_nan = df2020Grouped['_merge_CEQMCC']=='left_only'\n",
    "df2020Grouped.loc[bool_nan,'represent'] = 'Unidentified' ## for non-MCCs or those that haven't been identified\n",
    "\n",
    "bool_rep = df2020Grouped.loc[(~bool_nan),'title'].str.contains('Mass Mail Campaign '+r'\\b', regex=True, case=True)\n",
    "df2020Grouped.loc[bool_rep&(~bool_nan),['represent']] = 'Yes' ## for representative comments\n",
    "\n",
    "bool_notrep = df2020Grouped.loc[(~bool_nan),'title'].str.contains('MM[\\d]+ Comment'+r'\\b', regex=True, case=True)\n",
    "df2020Grouped.loc[bool_notrep&(~bool_nan),['represent']] = 'No' ## for grouped comments that aren't representative\n",
    "\n",
    "print(bool_nan.value_counts(), \n",
    "      bool_rep.value_counts(), \n",
    "      bool_notrep.value_counts(), sep='\\n\\n')\n",
    "\n",
    "df2020Grouped = df2020Grouped.astype({'represent': 'category'})\n",
    "print('\\n', \n",
    "      df2020Grouped.loc[:,'represent'].value_counts())\n",
    "\n",
    "# pivot against MCC filter\n",
    "pd.pivot_table(df2020Grouped, index=['represent'], values=['documentId'], columns=['MCCfilter'],\n",
    "               aggfunc='count', fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2020Grouped.query('represent == \"Yes\"').sort_values('MCCnumber', ascending=True)[['MCCnumber','documentId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create new DataFrame of Representative Comments ----- #\n",
    "\n",
    "# list of docIds for representative comments\n",
    "repIdList = df2020Grouped.query('represent == \"Yes\"').sort_values('MCCnumber', ascending=True)['documentId'].tolist()\n",
    "\n",
    "# create list of MMC, docId of earliest postedDate in MCC, docId of latest postedDate in MCC\n",
    "MCCList = []\n",
    "postedLast = []\n",
    "lastDate = []\n",
    "\n",
    "for MCC in range(1,120):\n",
    "    MCCList.extend([MCC])\n",
    "    postedLast.extend(df2020Grouped.query('MCCnumber == @MCC').\n",
    "                      sort_values('postedDate', ascending=False).head(1)['documentId'])\n",
    "    lastDate.extend(df2020Grouped.query('MCCnumber == @MCC').\n",
    "                    sort_values('postedDate', ascending=False, na_position='last').head(1)['postedDate'])\n",
    "\n",
    "# ----- Retrieve receivedDates for representative comments ----- #\n",
    "import requests\n",
    "\n",
    "# general variables for setting parameters\n",
    "APIkey = \"fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC\"\n",
    "baseURL = \"https://api.data.gov:443/regulations/v3/document.json?\"\n",
    "dctId = \"\"\n",
    "\n",
    "# set parameters\n",
    "params = {'api_key': APIkey,\n",
    "          'documentId': dctId}\n",
    "\n",
    "# using postedLast list\n",
    "range_last = len(postedLast)\n",
    "receivedLast = [] # list for adding receivedDate of each postedLast entry\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "for d in range(range_last):\n",
    "    dctId = postedLast[d]\n",
    "    params.update({'documentId': dctId})\n",
    "\n",
    "    dct_response = requests.get(baseURL, params=params)\n",
    "    RL_remaining = int(dct_response.headers['X-RateLimit-Remaining'])\n",
    "\n",
    "    if dct_response.status_code != 200:\n",
    "        print('code '+str(dct_response.status_code)+' for page #'+str(pageIndex), \n",
    "              dct_response.text, sep='\\n')\n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 1 minute...\", sep='\\n')\n",
    "        time.sleep(60)\n",
    "\n",
    "    this_receivedDate = dct_response.json()['receivedDate']\n",
    "    receivedLast.append(this_receivedDate)\n",
    "\n",
    "print('Length of receivedLast is '+str(len(receivedLast)))\n",
    "\n",
    "# ----- Generate df from the lists ----- #\n",
    "dateList = list(zip(repIdList, MCCList, postedLast, lastDate, receivedLast))\n",
    "dfRepresent = pd.DataFrame(dateList, columns = ['documentId', 'MCCnumber', 'lastId', 'lastDate', 'receivedDate'])\n",
    "dfRepresent['represent'] = 'Yes'\n",
    "dfRepresent = dfRepresent.astype({'represent': 'category'})\n",
    "dfRepresent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dfRepresent.loc[:,['MCCnumber','receivedDate']].sort_values('receivedDate', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRepresent = dfRepresent[['MCCnumber','lastId','lastDate','receivedDate']]\n",
    "dfRepresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2020Grouped))\n",
    "df2020Represent = df2020Grouped.merge(dfRepresent, how='outer', on=['MCCnumber'], indicator=True, validate='m:1')\n",
    "df2020Represent = df2020Represent.rename(columns={'_merge': '_merge_represent'})\n",
    "df2020Represent = df2020Represent.drop(columns=['commentDueDate','commentStartDate','openForComment'])\n",
    "df2020Represent = df2020Represent.fillna(value={'commentsGrouped': 0, \n",
    "                                                'MCCnumber': 0}, downcast='infer')\n",
    "df2020Represent = df2020Represent.astype({'MCCnumber': 'int64',\n",
    "                                          'commentsGrouped': 'int64', \n",
    "                                          'docketType': 'category', \n",
    "                                          'agencyBranch': 'category'})\n",
    "\n",
    "df2020Represent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020Represent['receivedDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Comments for Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df2020Represent, values=['documentId','commentsPosted','commentsReceived','commentsGrouped'],\n",
    "               index = ['MCCfilter'], aggfunc={'documentId': 'count',\n",
    "                                               'commentsPosted': np.sum,\n",
    "                                               'commentsReceived': np.sum,\n",
    "                                               'commentsGrouped': np.max}, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df2020Represent, values=['commentsPosted','commentsReceived'], columns=['represent'],\n",
    "                              index=['MCCfilter'],\n",
    "                              aggfunc={'commentsPosted':'count',\n",
    "                                       'commentsReceived': np.sum}, fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020Represent.query('represent == \"No\" & (MCCfilter==\"Both R&G\")').loc[:,['agencyParent','documentId','commentsReceived','commentsPosted','commentsGrouped','title','MCCnumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate two new columns for analysis of comments\n",
    "# first, number of comments including MCC totals\n",
    "df2020Represent['commentsWithMCC'] = np.nan\n",
    "\n",
    "bool_WithMCC = (df2020Represent['represent']=='Unidentified') ## comments where MCCs haven't been identified\n",
    "df2020Represent.loc[bool_WithMCC,'commentsWithMCC'] = df2020Represent.loc[bool_WithMCC,'commentsReceived']\n",
    "\n",
    "bool_WithMCC = (df2020Represent['represent']=='Yes') & (df2020Represent['MCCfilter']=='Both R&G') ## comments that I assigned to represent an MCC but commentsPosted!=commentsReceived (ie, metadata indicates additional commentReceived)\n",
    "df2020Represent.loc[bool_WithMCC,'commentsWithMCC'] = (df2020Represent.loc[bool_WithMCC,'commentsReceived'] + \n",
    "                                                       df2020Represent.loc[bool_WithMCC,'commentsGrouped'] - 1)\n",
    "\n",
    "bool_WithMCC = (df2020Represent['represent']=='Yes') & (df2020Represent['MCCfilter']=='Grouped') ## comments that I assigned to represent an MCC and commentsPosted==commentsReceived\n",
    "df2020Represent.loc[bool_WithMCC,'commentsWithMCC'] = df2020Represent.loc[bool_WithMCC,'commentsGrouped']\n",
    "\n",
    "bool_WithMCC = (df2020Represent['represent']=='No') & (df2020Represent['MCCfilter']=='Both R&G') ## comments grouped with an MCC representative but commentsPosted!=commentsReceived\n",
    "df2020Represent.loc[bool_WithMCC,'commentsWithMCC'] = df2020Represent.loc[bool_WithMCC,'commentsReceived']\n",
    "\n",
    "bool_WithMCC = (df2020Represent['represent']=='No') & (df2020Represent['MCCfilter']=='Grouped') ## comments grouped with an MCC representative and and commentsPosted==commentsReceived\n",
    "df2020Represent.loc[bool_WithMCC,'commentsWithMCC'] = 0\n",
    "\n",
    "print(df2020Represent['commentsWithMCC'].isna().value_counts(),'\\n')\n",
    "\n",
    "\n",
    "# second, number of comments excluding MCC totals (representative comments count as 1)\n",
    "df2020Represent['commentsNoMCC'] = np.nan\n",
    "\n",
    "bool_NoMCC = (df2020Represent['represent']=='Unidentified') ## comments where MCCs haven't been identified\n",
    "df2020Represent.loc[bool_NoMCC,'commentsNoMCC'] = df2020Represent.loc[bool_NoMCC,'commentsPosted']\n",
    "\n",
    "bool_NoMCC = (df2020Represent['represent']=='Yes') & (df2020Represent['MCCfilter']=='Both R&G') ## comments that I assigned to represent an MCC but commentsPosted!=commentsReceived\n",
    "df2020Represent.loc[bool_NoMCC,'commentsNoMCC'] = df2020Represent.loc[bool_NoMCC,'commentsPosted']\n",
    "\n",
    "bool_NoMCC = (df2020Represent['represent']=='Yes') & (df2020Represent['MCCfilter']=='Grouped') ## comments that I assigned to represent an MCC and commentsPosted==commentsReceived\n",
    "df2020Represent.loc[bool_NoMCC,'commentsNoMCC'] = df2020Represent.loc[bool_NoMCC,'commentsPosted']\n",
    "\n",
    "bool_NoMCC = (df2020Represent['represent']=='No') ## comments grouped with an MCC representative\n",
    "df2020Represent.loc[bool_NoMCC,'commentsNoMCC'] = 0\n",
    "\n",
    "print(df2020Represent['commentsNoMCC'].isna().value_counts(),'\\n')\n",
    "\n",
    "\n",
    "# convert new columns to integers\n",
    "df2020Represent = df2020Represent.astype({'commentsWithMCC': 'int64', \n",
    "                                          'commentsNoMCC': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate new column for analyzing comment dates; should fix issue with late posted comments\n",
    "df2020Represent['analysisDate'] = ''\n",
    "\n",
    "bool_date = df2020Represent['represent']=='Unidentified' ## comments where MCCs haven't been identified\n",
    "df2020Represent.loc[bool_date,'analysisDate'] = df2020Represent.loc[bool_date,'postedDate']\n",
    "\n",
    "bool_date = df2020Represent['represent']!='Unidentified' ## comments with identified MCCs\n",
    "df2020Represent.loc[bool_date,'analysisDate'] = df2020Represent.loc[bool_date,'receivedDate']\n",
    "\n",
    "print(df2020Represent['analysisDate'].isna().value_counts(),'\\n')\n",
    "print((df2020Represent['analysisDate']=='').value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df2020Represent, values=['receivedDate','postedDate','analysisDate'], index=['represent'],\n",
    "                              aggfunc='count', dropna=False, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns for year and month\n",
    "df2020Represent['analysisYear'] = df2020Represent['analysisDate'].str.slice(start=0,stop=4)\n",
    "df2020Represent['analysisMonth'] = df2020Represent['analysisDate'].str.slice(start=6,stop=7)\n",
    "\n",
    "# convert to integers\n",
    "df2020Represent = df2020Represent.astype({'analysisYear': 'int64', \n",
    "                                          'analysisMonth': 'int64'})\n",
    "\n",
    "# return new columns\n",
    "print(df2020Represent.loc[:,['analysisYear','analysisMonth']].dtypes)\n",
    "df2020Represent.loc[:,['analysisYear','analysisMonth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Results // Export for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot comments (excluding MCCs)\n",
    "\n",
    "pd.pivot_table(df2020Represent, values=['commentsNoMCC'], columns=['postedMonth'],\n",
    "                              index=['analysisMonth'],\n",
    "                              aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot comments (including MCCs)\n",
    "\n",
    "pd.pivot_table(df2020Represent, values=['commentsWithMCC'], columns=['postedMonth'],\n",
    "                              index=['analysisMonth'],\n",
    "                              aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2020Represent.columns.tolist(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe for analysis\n",
    "write_columns = ['agencyBranch', 'agencyParent', 'agencyAcronym', 'docketId', 'docketType', \n",
    "                 'documentId', 'submitterName', 'title', 'organization', 'attachmentCount', \n",
    "                 'analysisDate', 'analysisYear', 'analysisMonth', \n",
    "                 'commentsWithMCC', 'commentsNoMCC', \n",
    "                 'MCCfilter', 'MCCnumber', 'represent']\n",
    "\n",
    "savePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/Annual/\"\n",
    "saveFile = 'cleaned_PS_2020.csv'\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+saveFile, 'w', encoding='utf-8') as outfile:\n",
    "    df2020Represent.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
