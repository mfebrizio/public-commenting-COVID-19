{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Commenting in a Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ijson\n",
    "import time\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the folder where the data are saved\n",
    "filePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/API/\"\n",
    "savePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/Annual/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test URL\n",
    "dateRange = \"01/01/18-05/31/18\"\n",
    "testURL = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate&po=0&rpp=1000&api_key=fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC&pd=\"\n",
    "\n",
    "print(testURL+dateRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check retrieval dates\n",
    "with open(filePath+'_date accessed.txt', 'r') as infile:\n",
    "    dfAccessed = pd.read_csv(infile)\n",
    "\n",
    "dfAccessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fileName = 'endpoint_documents_PS_2020Jan01_2020May31.json'\n",
    "data2020 = [] ## object for appending each comment\n",
    "comment_dict = {} ## dictionary for holding a single comment's metadata at a time\n",
    "\n",
    "with open(filePath+fileName, 'r', encoding='utf-8') as ijfile:\n",
    "    parser = ijson.parse(ijfile)\n",
    "    for prefix, event, value in parser:\n",
    "        if prefix=='':\n",
    "            if event=='start_array':\n",
    "                continue\n",
    "            elif event=='end_array':\n",
    "                break\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        elif prefix=='item':\n",
    "            if event=='start_map':\n",
    "                continue\n",
    "            elif event=='end_map':\n",
    "                data2020.append(comment_dict)\n",
    "                comment_dict = {}\n",
    "                continue\n",
    "            elif event=='map_key':\n",
    "                dict_key = value\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        else:\n",
    "            comment_dict.update({dict_key: value})\n",
    "\n",
    "print(len(data2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse comments in object\n",
    "data2020[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# convert to pandas DataFrame\n",
    "df2020 = pd.DataFrame(data2020)\n",
    "df2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfColumns = df2020.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "saveFile = 'endpoint_documents_PS_2020.csv'\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+saveFile, 'w', encoding='utf-8') as outfile:\n",
    "    df2020.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fileName = 'endpoint_documents_PS_2019Jan01_2019May31.json'\n",
    "data2019 = [] ## object for appending each comment\n",
    "comment_dict = {} ## dictionary for holding a single comment's metadata at a time\n",
    "\n",
    "with open(filePath+fileName, 'r', encoding='utf-8') as ijfile:\n",
    "    parser = ijson.parse(ijfile)\n",
    "    for prefix, event, value in parser:\n",
    "        if prefix=='':\n",
    "            if event=='start_array':\n",
    "                continue\n",
    "            elif event=='end_array':\n",
    "                break\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        elif prefix=='item':\n",
    "            if event=='start_map':\n",
    "                continue\n",
    "            elif event=='end_map':\n",
    "                data2019.append(comment_dict)\n",
    "                comment_dict = {}\n",
    "                continue\n",
    "            elif event=='map_key':\n",
    "                dict_key = value\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        else:\n",
    "            comment_dict.update({dict_key: value})\n",
    "\n",
    "print(len(data2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse comments in object\n",
    "data2019[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# convert to pandas DataFrame\n",
    "df2019 = pd.DataFrame(data2019)\n",
    "df2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfColumns = df2019.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "saveFile = 'endpoint_documents_PS_2019.csv'\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+saveFile, 'w', encoding='utf-8') as outfile:\n",
    "    df2019.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fileName = 'endpoint_documents_PS_2018Jan01_2018May31.json'\n",
    "data2018 = [] ## object for appending each comment\n",
    "comment_dict = {} ## dictionary for holding a single comment's metadata at a time\n",
    "\n",
    "with open(filePath+fileName, 'r', encoding='utf-8') as ijfile:\n",
    "    parser = ijson.parse(ijfile)\n",
    "    for prefix, event, value in parser:\n",
    "        if prefix=='':\n",
    "            if event=='start_array':\n",
    "                continue\n",
    "            elif event=='end_array':\n",
    "                break\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        elif prefix=='item':\n",
    "            if event=='start_map':\n",
    "                continue\n",
    "            elif event=='end_map':\n",
    "                data2018.append(comment_dict)\n",
    "                comment_dict = {}\n",
    "                continue\n",
    "            elif event=='map_key':\n",
    "                dict_key = value\n",
    "            else:\n",
    "                print('check: '+str(prefix))\n",
    "        else:\n",
    "            comment_dict.update({dict_key: value})\n",
    "\n",
    "print(len(data2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse comments in object\n",
    "data2018[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# convert to pandas DataFrame\n",
    "df2018 = pd.DataFrame(data2018)\n",
    "df2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfColumns = df2018.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "saveFile = 'endpoint_documents_PS_2018.csv'\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+saveFile, 'w', encoding='utf-8') as outfile:\n",
    "    df2018.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2017 = pd.read_json(filePath+'endpoint_documents_PS_2017Jan01_2017May31.json')\n",
    "\n",
    "df2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2017.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2017.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2017.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2016 = pd.read_json(filePath+'endpoint_documents_PS_2016Jan01_2016May31.json')\n",
    "\n",
    "df2016.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2016.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2016.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2016.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2015 = pd.read_json(filePath+'endpoint_documents_PS_2015Jan01_2015May31.json')\n",
    "\n",
    "df2015.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2015.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2015.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2015.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2014 = pd.read_json(filePath+'endpoint_documents_PS_2014Jan01_2014May31.json')\n",
    "\n",
    "df2014.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2014.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2014.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2014.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2013 = pd.read_json(filePath+'endpoint_documents_PS_2013Jan01_2013May31.json')\n",
    "\n",
    "df2013.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2013.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2013.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2013.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df2012 = pd.read_json(filePath+'endpoint_documents_PS_2012Jan01_2012May31.json')\n",
    "\n",
    "df2012.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfColumns = df2012.columns.tolist()\n",
    "print(dfColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_columns = ['agencyAcronym','attachmentCount','commentDueDate','commentStartDate','docketId',\n",
    "                 'docketType','documentId','numberOfCommentsReceived','openForComment','postedDate',\n",
    "                 'submitterName','title','organization']\n",
    "\n",
    "# write to csv, reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "with open(savePath+'endpoint_documents_PS_2012.csv', 'w', encoding='utf-8') as outfile:\n",
    "    df2012.to_csv(outfile, index_label='index', line_terminator='\\n', columns=write_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
