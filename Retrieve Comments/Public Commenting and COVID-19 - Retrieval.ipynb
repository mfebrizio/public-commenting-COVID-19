{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Commenting in a Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Comments\n",
    "\n",
    "January through May for each year (2012 to 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "API documentation: https://regulationsgov.github.io/developers/basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# datetime package too: https://docs.python.org/3/library/datetime.html\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the folder where the data are saved\n",
    "filePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/API/\"\n",
    "\n",
    "# general variables for setting parameters\n",
    "APIkey = \"fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC\"\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint: documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2020 - May 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/20'\n",
    "pdEnd = '05/31/20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2020Jan01_2020May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS // rpp + 1),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS // rpp + 1))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS // rpp + 1) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2020Jan01_2020May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2019 - May 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/19'\n",
    "pdEnd = '05/31/19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2019Jan01_2019May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2019Jan01_2019May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2018 - May 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/18'\n",
    "pdEnd = '05/31/18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2018Jan01_2018May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2018Jan01_2018May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2017 - May 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/17'\n",
    "pdEnd = '05/31/17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2017Jan01_2017May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2017Jan01_2017May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2016 - May 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/16'\n",
    "pdEnd = '05/31/16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2016Jan01_2016May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2016Jan01_2016May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2015 - May 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/15'\n",
    "pdEnd = '05/31/15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2015Jan01_2015May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2015Jan01_2015May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2014 - May 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/14'\n",
    "pdEnd = '05/31/14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2014Jan01_2014May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2014Jan01_2014May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2013 - May 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/13'\n",
    "pdEnd = '05/31/13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2013Jan01_2013May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2013Jan01_2013May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2012 - May 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp\n",
    "\n",
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/12'\n",
    "pdEnd = '05/31/12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2012Jan01_2012May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS//rpp + (1 if (numPS%rpp>0) else 0)),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS//rpp + (1 if (numPS%rpp>0) else 0)) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2012Jan01_2012May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
