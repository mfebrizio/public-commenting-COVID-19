{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Commenting in a Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "API documentation: https://regulationsgov.github.io/developers/basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# datetime package too: https://docs.python.org/3/library/datetime.html\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test datetime -- CAN SKIP\n",
    "now = datetime.now()\n",
    "print(\"recorded time is \" + str(now))\n",
    "\n",
    "timeIndices = []\n",
    "totalIndices = 5\n",
    "for index in range(0,5):\n",
    "    timeIndices.append(now)\n",
    "\n",
    "later = now + timedelta(seconds = 5)\n",
    "print(\"later time is \" + str(later))\n",
    "\n",
    "while True:\n",
    "    currTime = datetime.now()\n",
    "    if (currTime < later):\n",
    "        print(\"not yet\")\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(\"finally waited long enough\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test retrieving chunk time -- CAN SKIP\n",
    "t1 = 1*60+58\n",
    "c1 = 20000\n",
    "cx = numPS\n",
    "tx = t1*cx/c1\n",
    "\n",
    "print(str(round(tx))+' seconds')\n",
    "print(str(round(tx//60))+' minutes, '+str(round(tx%60))+' seconds')\n",
    "print(str(round(tx/60//60))+' hours, '+str(round(tx/60%60))+' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the folder where the data are saved\n",
    "filePath = \"C:/Users/mark/Box Sync/_MF/Assignments/Insights/Public Commenting and COVID-19/Data/\"\n",
    "\n",
    "# general variables for setting parameters\n",
    "APIkey = \"fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC\"\n",
    "rpp = 1000\n",
    "pageIndex = 0\n",
    "po = pageIndex * rpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint: documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2020 - May 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for setting parameters: document type = Public Submission\n",
    "baseURL_PS = \"https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate\"\n",
    "pdStart = '01/01/20'\n",
    "pdEnd = '05/31/20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Request URL: https://api.data.gov/regulations/v3/documents.json?encoded=1&countsOnly=0&dct=PS&so=ASC&sb=postedDate&po=0&rpp=1000&api_key=fYTx9mVjuwc2ZSsdqmbgdtSqx7HGUd3aCRkiH6bC&pd=01%2F01%2F20-05%2F31%2F20\n",
      "\n",
      "Total number of records requested: 1368250\n",
      "Number retrieved: 1000\n",
      "\n",
      "Determine how many pages of records need to be combined via the extend method...\n",
      "Start with: 1369\n",
      "That would be enough to retrieve 1369000 records -- a margin of 750 records.\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set parameters to retrieve PS documents\n",
    "params = {'po': po,\n",
    "          'rpp': rpp,\n",
    "          'api_key': APIkey,\n",
    "          'pd': pdStart+'-'+pdEnd}\n",
    "\n",
    "# retrieve comments using Requests library and check GET request response \n",
    "dcts_response = requests.get(baseURL_PS, params=params)\n",
    "RL_remaining = int(dcts_response.headers['X-RateLimit-Remaining'])\n",
    "print(\"Status Code: \"+str(dcts_response.status_code),\n",
    "      'Request URL: '+str(dcts_response.request.url)+'\\n',sep='\\n')\n",
    "\n",
    "# nested list: separate 'documents' from 'totalNumRecords'\n",
    "# confirm total requested and number of documents retrieved\n",
    "numPS = dcts_response.json()['totalNumRecords']\n",
    "dctsPS = dcts_response.json()['documents']\n",
    "print('Total number of records requested: '+str(numPS), 'Number retrieved: '+str(len(dctsPS)), sep='\\n')\n",
    "\n",
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_'+pdStart+'-'+pdEnd+'.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS, outfile, ensure_ascii=False, indent=4)    \n",
    "    print('Exported as JSON!')\n",
    "        \n",
    "else:\n",
    "    print('\\n''Determine how many pages of records need to be combined via the extend method...',\n",
    "          'Start with: '+str(numPS // rpp + 1),\n",
    "          'That would be enough to retrieve '+str(rpp * (numPS // rpp + 1))+' records'\n",
    "          ' -- a margin of '+str(rpp * (numPS // rpp + 1) - numPS)+' records.',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length of data: 0\n",
      "Time array length: 1000\n",
      "nextAllowableTimeIndex = 0  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:35:09.451395\n",
      "request made (pageIndex = 0)\n",
      "Retrieved: 1000 \n",
      "\n",
      "nextAllowableTimeIndex = 100  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:37:36.397942\n",
      "request made (pageIndex = 100)\n",
      "Retrieved: 101000 \n",
      "\n",
      "nextAllowableTimeIndex = 200  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:39:33.201408\n",
      "request made (pageIndex = 200)\n",
      "Retrieved: 201000 \n",
      "\n",
      "nextAllowableTimeIndex = 300  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:43:15.629961\n",
      "request made (pageIndex = 300)\n",
      "Retrieved: 301000 \n",
      "\n",
      "nextAllowableTimeIndex = 400  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:45:28.055897\n",
      "request made (pageIndex = 400)\n",
      "Retrieved: 401000 \n",
      "\n",
      "nextAllowableTimeIndex = 500  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:47:52.096385\n",
      "request made (pageIndex = 500)\n",
      "Retrieved: 501000 \n",
      "\n",
      "nextAllowableTimeIndex = 600  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:53:51.273573\n",
      "request made (pageIndex = 600)\n",
      "Retrieved: 601000 \n",
      "\n",
      "nextAllowableTimeIndex = 700  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 22:59:49.813011\n",
      "request made (pageIndex = 700)\n",
      "Retrieved: 701000 \n",
      "\n",
      "nextAllowableTimeIndex = 800  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 23:02:20.727035\n",
      "request made (pageIndex = 800)\n",
      "Retrieved: 801000 \n",
      "\n",
      "Rate Limit remaining: 100\n",
      "nextAllowableTimeIndex = 900  nextAllowableTime = 2020-06-16 22:35:09.451395  currentTime = 2020-06-16 23:04:42.376899\n",
      "request made (pageIndex = 900)\n",
      "Retrieved: 901000 \n",
      "\n",
      "Rate Limit remaining: 75\n",
      "Rate Limit remaining: 50\n",
      "Rate Limit remaining: 25\n",
      "Rate Limit remaining: 9\n",
      "sleeping 5 minutes...\n",
      "Rate Limit remaining: 8\n",
      "sleeping 5 minutes...\n",
      "Rate Limit remaining: 7\n",
      "sleeping 5 minutes...\n",
      "Rate Limit remaining: 8\n",
      "sleeping 5 minutes...\n",
      "Rate Limit remaining: 9\n",
      "sleeping 5 minutes...\n",
      "Rate Limit remaining: 9\n",
      "sleeping 5 minutes...\n",
      "nextAllowableTimeIndex = 0  nextAllowableTime = 2020-06-16 23:35:09.451395  currentTime = 2020-06-16 23:39:23.565004\n",
      "request made (pageIndex = 1000)\n",
      "Retrieved: 1001000 \n",
      "\n",
      "nextAllowableTimeIndex = 100  nextAllowableTime = 2020-06-16 23:37:36.397942  currentTime = 2020-06-16 23:42:10.929750\n",
      "request made (pageIndex = 1100)\n",
      "Retrieved: 1101000 \n",
      "\n",
      "nextAllowableTimeIndex = 200  nextAllowableTime = 2020-06-16 23:39:33.201408  currentTime = 2020-06-16 23:45:02.434907\n",
      "request made (pageIndex = 1200)\n",
      "Retrieved: 1201000 \n",
      "\n",
      "nextAllowableTimeIndex = 300  nextAllowableTime = 2020-06-16 23:43:15.629961  currentTime = 2020-06-16 23:47:36.470015\n",
      "request made (pageIndex = 1300)\n",
      "Retrieved: 1301000 \n",
      "\n",
      "If this works, we should have retrieved all the requested documents: 1368250\n",
      "Wall time: 1h 14min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define empty object to put extended data\n",
    "dctsPS_all = []\n",
    "totalNumPages = numPS//rpp + (1 if (numPS%rpp>0) else 0)\n",
    "print('Initial length of data: '+str(len(dctsPS_all)))\n",
    "\n",
    "# define time objects for avoiding rate limit\n",
    "initialNextTime = datetime.now()\n",
    "nextAllowableTime = []\n",
    "pagesPerHour = 1000 ## regulations.gov rate limit of 1000\n",
    "\n",
    "# fill array of allowable times\n",
    "for index in range(0,pagesPerHour):\n",
    "    nextAllowableTime.append(initialNextTime)\n",
    "print('Time array length: '+str(len(nextAllowableTime)))\n",
    "\n",
    "# retrieve additional pages of documents and extend object\n",
    "for pageIndex in range (0,totalNumPages): ## remember range is non-inclusive\n",
    "    \n",
    "    if RL_remaining < 10:\n",
    "        print('Rate Limit remaining: '+str(RL_remaining),\n",
    "              \"sleeping 5 minutes...\", sep='\\n')\n",
    "        time.sleep(300)\n",
    "    elif (RL_remaining <= 100) & (RL_remaining%25==0):\n",
    "        print('Rate Limit remaining: '+str(RL_remaining))\n",
    "    \n",
    "    nextAllowableTimeIndex = pageIndex % pagesPerHour\n",
    "    currentTime = datetime.now()\n",
    "    if pageIndex%100 == 0:\n",
    "        print(\"nextAllowableTimeIndex = \"+str(nextAllowableTimeIndex),\n",
    "              \"nextAllowableTime = \"+str(nextAllowableTime[nextAllowableTimeIndex]),\n",
    "              \"currentTime = \"+str(currentTime), sep=\"  \")\n",
    "\n",
    "    if currentTime < nextAllowableTime[nextAllowableTimeIndex]:\n",
    "        waitTime = nextAllowableTime[nextAllowableTimeIndex] - currentTime\n",
    "        print(\"sleeping \" + str(waitTime.total_seconds()) + \" seconds...\")\n",
    "        time.sleep(waitTime.total_seconds() + 0.01)\n",
    "    \n",
    "    if nextAllowableTime[nextAllowableTimeIndex] <= datetime.now():\n",
    "        nextAllowableTime[nextAllowableTimeIndex] = datetime.now() + timedelta(seconds = 3600) ## add one hour to nextAllowableTime\n",
    "\n",
    "        try:\n",
    "            po = pageIndex * rpp\n",
    "            params.update({'po': po})\n",
    "            temp_response = requests.get(baseURL_PS, params=params)\n",
    "            RL_remaining = int(temp_response.headers['X-RateLimit-Remaining'])\n",
    "            if temp_response.status_code != 200: ## status code = 429 means over rate limit\n",
    "                print('code '+str(temp_response.status_code)+' for page #'+str(pageIndex),\n",
    "                      temp_response.text, sep='\\n')\n",
    "\n",
    "            data_this_page = temp_response.json()['documents']\n",
    "            dctsPS_all.extend(data_this_page)\n",
    "            if pageIndex%100 == 0:\n",
    "                print(\"request made (pageIndex = \" + str(pageIndex) + \")\")\n",
    "                print('Retrieved: '+str(len(dctsPS_all)),'\\n')\n",
    "        except:\n",
    "            print('missing page: '+str(pageIndex))\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print(\"request failed\")\n",
    "        print(\"too soon -- breaking (pageIndex = \"+str(pageIndex)+\")\")\n",
    "        break\n",
    "\n",
    "print('If this works, we should have retrieved all the requested documents: '+str(len(dctsPS_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported as JSON!\n"
     ]
    }
   ],
   "source": [
    "# if requested == retrieved, then export as JSON\n",
    "if len(dctsPS_all)==numPS:\n",
    "    with open(filePath+'endpoint_documents_PS_2020Jan01_2020May31.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(dctsPS_all, outfile, ensure_ascii=False, indent=4)\n",
    "    print('Exported as JSON!')\n",
    "\n",
    "else:\n",
    "    print('Export unsuccessful. Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Comments: Jan 2019 - May 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
